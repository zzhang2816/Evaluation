{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "torch.manual_seed(42)\n",
    "from utils import train\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=np.load(\"dataset/train.npz\")\n",
    "val_set=np.load(\"dataset/val.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.X=torch.tensor(dataset['x'],dtype = torch.float32)\n",
    "        self.y=torch.tensor(dataset['y'],dtype = torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.X[index],self.y[index]\n",
    "\n",
    "def generate_dataloaders(train_data,val_data,batch_size):\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    X, y=next(iter(train_loader))\n",
    "    print(f'TRAIN: the shape of X: {X.shape}; the shape of y: {y.shape}')\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "    X, y=next(iter(val_loader))\n",
    "    print(f'VAL: the shape of X: {X.shape}; the shape of y: {y.shape}')\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: the shape of X: torch.Size([32, 8, 49]); the shape of y: torch.Size([32, 1])\n",
      "VAL: the shape of X: torch.Size([32, 8, 49]); the shape of y: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "train_data = Mydataset(train_set)\n",
    "val_data = Mydataset(val_set)\n",
    "train_loader, val_loader=generate_dataloaders(train_data, val_data,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \"\"\"The RNN model.\"\"\"\n",
    "    def __init__(self, input_dimension,output_dimension,num_layers,num_hiddens):\n",
    "        super().__init__()\n",
    "        self.input_dimension = input_dimension\n",
    "        self.output_dimension=output_dimension\n",
    "        self.num_hiddens=num_hiddens\n",
    "        self.rnn = nn.LSTM(self.input_dimension, self.num_hiddens,num_layers)\n",
    "        self.linear = nn.Linear(self.num_hiddens, self.output_dimension)\n",
    "\n",
    "    def forward(self, inputs,state=None):\n",
    "        X = inputs.permute(1,0,2)\n",
    "        X = X.to(torch.float32)\n",
    "        _, state = self.rnn(X)\n",
    "        # if state is not None:\n",
    "        #     _,state = self.rnn(X, state)\n",
    "        # else:\n",
    "        #     _, state = self.rnn(X)\n",
    "        output = self.linear(state[-1][-1]) # take the hidden state 2, on the layer 2\n",
    "        return output\n",
    "    \n",
    "    # def begin_state(self, device, batch_size=1):\n",
    "    #     if not isinstance(self.rnn, nn.LSTM):\n",
    "    #         # `nn.GRU` takes a tensor as hidden state\n",
    "    #         return torch.zeros((self.rnn.num_layers,\n",
    "    #                             batch_size, self.num_hiddens), device=device)\n",
    "    #     else:\n",
    "    #         # `nn.LSTM` takes a tuple of hidden states\n",
    "    #         return (torch.zeros((self.rnn.num_layers,\n",
    "    #                              batch_size, self.num_hiddens),\n",
    "    #                             device=device),\n",
    "    #                 torch.zeros((self.rnn.num_layers,\n",
    "    #                              batch_size, self.num_hiddens),\n",
    "    #                             device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb=False\n",
    "net = RNNModel(input_dimension=49,output_dimension=1,num_layers=2,num_hiddens=8)\n",
    "num_epochs=5\n",
    "load_from_path=None\n",
    "save_to_path=\"checkpoints/v0/\"\n",
    "if use_wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(project=\"trial\", config={'lr':0.001,'num_layers':2,'num_hiddens':8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trail\n",
    "X_sample, _ =next(iter(train_loader))\n",
    "y_trail=net(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_trail.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb3ee2cb987f0791d59217aac9c93edb0025d3eec1e91adab0e3ff51219fcd98"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('areix': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
