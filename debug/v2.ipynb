{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "torch.manual_seed(42)\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import wandb\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=np.load(\"dataset/train.npz\")\n",
    "val_set=np.load(\"dataset/val.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        self.X=torch.tensor(dataset['x'],dtype = torch.float32)\n",
    "        self.y=torch.tensor(dataset['y'],dtype = torch.float32)\n",
    "        self.locations=torch.tensor(dataset['locations'],dtype = torch.int)\n",
    "        self.times=torch.tensor(dataset['times'],dtype = torch.int)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.X[index],self.y[index],self.locations[index],self.times[index]\n",
    "\n",
    "def generate_dataloaders(train_data,val_data,batch_size):\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    X, y,locations,times=next(iter(train_loader))\n",
    "    print(f'TRAIN: the shape of X: {X.shape}; the shape of y: {y.shape}\\\n",
    "the shape of locations: {locations.shape};the shape of times: {times.shape};')\n",
    "\n",
    "    val_loader = DataLoader(dataset=val_data, batch_size=batch_size, shuffle=True)\n",
    "    X, y,locations,times=next(iter(val_loader))\n",
    "    print(f'VAL: the shape of X: {X.shape}; the shape of y: {y.shape}\\\n",
    "the shape of locations: {locations.shape};the shape of times: {times.shape};')\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: the shape of X: torch.Size([32, 8, 49]); the shape of y: torch.Size([32, 1])the shape of locations: torch.Size([32, 2]);the shape of times: torch.Size([32]);\n",
      "VAL: the shape of X: torch.Size([32, 8, 49]); the shape of y: torch.Size([32, 1])the shape of locations: torch.Size([32, 2]);the shape of times: torch.Size([32]);\n"
     ]
    }
   ],
   "source": [
    "train_data = Mydataset(train_set)\n",
    "val_data = Mydataset(val_set)\n",
    "train_loader, val_loader=generate_dataloaders(train_data, val_data,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n",
    "        super(AdditiveAttention, self).__init__(**kwargs)\n",
    "        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n",
    "        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n",
    "        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, queries, keys, values):\n",
    "        queries, keys = self.W_q(queries), self.W_k(keys)\n",
    "        features = queries + keys\n",
    "        features = torch.tanh(features)\n",
    "        scores = self.w_v(features).squeeze(-1)\n",
    "        attention_weights = torch.softmax(scores, dim=-1) \n",
    "        # bmm: (batch_sz, 1, num_hiddens) = (batch_sz, 1, key_size) * (batch_sz, key_size, num_hiddens)\n",
    "        output = torch.bmm(self.dropout(attention_weights.unsqueeze(1)), values)\n",
    "        output = output.squeeze(1) # (batch_sz, num_hiddens)\n",
    "        return output\n",
    "\n",
    "class Model_v2(nn.Module):\n",
    "    \"\"\"concat the GRU output and categorical embeddings, feed into MLP.\"\"\"\n",
    "    def __init__(self, my_confg):\n",
    "        super().__init__()\n",
    "        self.loc_x_embedLayer=nn.Embedding(my_confg.loc_dim,my_confg.embed_loc_size)\n",
    "        self.loc_y_embedLayer=nn.Embedding(my_confg.loc_dim,my_confg.embed_loc_size)\n",
    "        self.time_embedLayer=nn.Embedding(my_confg.time_dim,my_confg.embed_time_size)\n",
    "        self.rnn = nn.GRU(my_confg.X_dim, my_confg.num_hiddens,my_confg.num_layers)\n",
    "        concat_dim = 2*my_confg.embed_loc_size+my_confg.embed_time_size\n",
    "        self.attention = AdditiveAttention(my_confg.num_hiddens, concat_dim,\n",
    "                                               my_confg.num_hiddens, my_confg.dropout)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(my_confg.num_hiddens, my_confg.l_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(my_confg.l_dim, my_confg.output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, X, locations,times, state=None):\n",
    "        X = X.permute(1,0,2)\n",
    "        X = X.to(torch.float32)\n",
    "        y, _ = self.rnn(X)\n",
    "        loc_embedding = torch.cat((self.loc_x_embedLayer(locations[:,0]),\n",
    "                    self.loc_y_embedLayer(locations[:,1])),axis=1)\n",
    "        time_embedding = self.time_embedLayer(times)\n",
    "        categorical_embedding = torch.cat((loc_embedding,time_embedding),axis=1)\n",
    "        key_value = y.permute(1, 0, 2)\n",
    "        output = self.attention(torch.unsqueeze(categorical_embedding, dim=1),key_value,key_value)\n",
    "        output = self.mlp(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_confg={\n",
    "    # Training confg\n",
    "    'num_epochs': 10,\n",
    "    'load_from_path': None,\n",
    "    'save_to_path': \"checkpoints/v1/\",\n",
    "    'use_wandb': False,\n",
    "    # Categorical Embeddings\n",
    "    'loc_dim':10, # dataset-specific\n",
    "    'embed_loc_size':5,\n",
    "    'time_dim':24, # dataset-specific\n",
    "    'embed_time_size':10,\n",
    "    # GRU\n",
    "    'X_dim':49, # dataset-specific\n",
    "    'num_hiddens':8,\n",
    "    'num_layers':2,\n",
    "    # MLP\n",
    "    'l_dim':16,\n",
    "    'output_dim':1, # dataset-specific\n",
    "    # Attention\n",
    "    'dropout':0\n",
    "}\n",
    "my_confg = argparse.Namespace(**my_confg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model_v2(my_confg)\n",
    "if my_confg.use_wandb:\n",
    "    wandb.login()\n",
    "    wandb.init(project=\"trial\", config={'lr':0.001,'num_layers':2,'num_hiddens':8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trail\n",
    "X_sample, _ ,loc_sample,time_sample =next(iter(train_loader))\n",
    "y_trail=net(X_sample,loc_sample,time_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eb3ee2cb987f0791d59217aac9c93edb0025d3eec1e91adab0e3ff51219fcd98"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('areix': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
